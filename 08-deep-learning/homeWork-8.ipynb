{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-22 19:34:11--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
      "Resolving github.com (github.com)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231122T183411Z&X-Amz-Expires=300&X-Amz-Signature=f60a2a082f6d98d3b45fd2453882d51209bf2796fe09594cf97a4cbab13d52f8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-11-22 19:34:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231122T183411Z&X-Amz-Expires=300&X-Amz-Signature=f60a2a082f6d98d3b45fd2453882d51209bf2796fe09594cf97a4cbab13d52f8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 117446836 (112M) [application/octet-stream]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>] 112.01M  11.4MB/s    in 10s     \n",
      "\n",
      "2023-11-22 19:34:22 (11.0 MB/s) - ‘data.zip’ saved [117446836/117446836]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q data.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:00:38.294511: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44859392 exceeds 10% of free system memory.\n",
      "2023-11-22 20:00:38.393607: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44859392 exceeds 10% of free system memory.\n",
      "2023-11-22 20:00:38.422945: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44859392 exceeds 10% of free system memory.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Convolutional layer with 32 filters, kernel size of (3, 3), and 'relu' activation\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
    "\n",
    "# Add a MaxPooling layer with pool size (2, 2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the multi-dimensional result\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a Dense layer with 64 neurons and 'relu' activation\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron and 'sigmoid' activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model using SGD optimizer with specified parameters\n",
    "sgd = SGD(lr=0.002, momentum=0.8)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import numpy as np\n",
    "\n",
    "# Define the data generators for train and test sets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Specify the paths to your train and test directories\n",
    "train_dir = 'data/train/'\n",
    "test_dir = 'data/test/'\n",
    "\n",
    "# Set the class_mode parameter to 'binary' for binary classification\n",
    "class_mode = 'binary'\n",
    "\n",
    "# Create the generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 103s 559ms/step - loss: 0.0604 - accuracy: 0.9888 - val_loss: 1.0670 - val_accuracy: 0.7440\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 90s 488ms/step - loss: 0.1164 - accuracy: 0.9657 - val_loss: 0.9050 - val_accuracy: 0.7658\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 91s 492ms/step - loss: 0.0456 - accuracy: 0.9916 - val_loss: 1.2837 - val_accuracy: 0.7331\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 95s 515ms/step - loss: 0.0228 - accuracy: 0.9970 - val_loss: 1.1895 - val_accuracy: 0.7320\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 89s 483ms/step - loss: 0.0248 - accuracy: 0.9978 - val_loss: 1.3934 - val_accuracy: 0.7015\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 94s 509ms/step - loss: 0.0247 - accuracy: 0.9981 - val_loss: 1.2470 - val_accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 92s 501ms/step - loss: 0.0402 - accuracy: 0.9921 - val_loss: 1.4006 - val_accuracy: 0.7179\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 87s 470ms/step - loss: 0.0125 - accuracy: 0.9989 - val_loss: 1.3457 - val_accuracy: 0.7375\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 83s 450ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 1.4110 - val_accuracy: 0.7320\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 95s 514ms/step - loss: 0.0163 - accuracy: 0.9992 - val_loss: 1.3119 - val_accuracy: 0.7505\n",
      "Median Training Accuracy: 0.9974163770675659\n",
      "Standard Deviation of Training Loss: 0.03045469539413689\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "\n",
    "# Access the training accuracy and loss for each epoch\n",
    "training_accuracy = history.history['accuracy']\n",
    "training_loss = history.history['loss']\n",
    "\n",
    "# Calculate the median of training accuracy\n",
    "median_training_accuracy = np.median(training_accuracy)\n",
    "\n",
    "# Calculate the standard deviation of training loss\n",
    "std_training_loss = np.std(training_loss)\n",
    "\n",
    "print(f\"Median Training Accuracy: {median_training_accuracy}\")\n",
    "print(f\"Standard Deviation of Training Loss: {std_training_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 139s 755ms/step - loss: 0.5802 - accuracy: 0.7294 - val_loss: 0.5162 - val_accuracy: 0.7647\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 97s 529ms/step - loss: 0.5032 - accuracy: 0.7713 - val_loss: 0.5055 - val_accuracy: 0.7930\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 130s 708ms/step - loss: 0.4895 - accuracy: 0.7740 - val_loss: 0.4808 - val_accuracy: 0.8039\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 144s 784ms/step - loss: 0.4755 - accuracy: 0.7860 - val_loss: 0.5090 - val_accuracy: 0.7832\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 124s 673ms/step - loss: 0.4771 - accuracy: 0.7890 - val_loss: 0.4519 - val_accuracy: 0.8007\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 136s 739ms/step - loss: 0.4730 - accuracy: 0.7868 - val_loss: 0.4710 - val_accuracy: 0.7963\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 142s 775ms/step - loss: 0.4728 - accuracy: 0.7824 - val_loss: 0.4879 - val_accuracy: 0.7919\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 120s 653ms/step - loss: 0.4581 - accuracy: 0.7977 - val_loss: 0.4523 - val_accuracy: 0.7985\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 118s 641ms/step - loss: 0.4534 - accuracy: 0.7993 - val_loss: 0.4594 - val_accuracy: 0.8115\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 149s 799ms/step - loss: 0.4579 - accuracy: 0.7960 - val_loss: 0.4528 - val_accuracy: 0.8017\n",
      "Mean Test Loss for Model Trained with Augmentations: 0.4786749541759491\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Define the data generators with augmentations for training and test sets\n",
    "augmented_train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_train_generator = augmented_train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Continue training the existing model for 10 more epochs\n",
    "history_augmented = model.fit(\n",
    "    augmented_train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "\n",
    "# Access the test loss for each epoch\n",
    "test_loss_augmented = history_augmented.history['val_loss']\n",
    "\n",
    "# Calculate the mean of test loss for all epochs\n",
    "mean_test_loss_augmented = np.mean(test_loss_augmented)\n",
    "\n",
    "print(f\"Mean Test Loss for Model Trained with Augmentations: {mean_test_loss_augmented}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Loss for Model Trained with Augmentations for All Epochs: 0.8670801758766175\n"
     ]
    }
   ],
   "source": [
    "# Access the test loss for each epoch\n",
    "all_test_losses = history.history[\"val_loss\"] + history_augmented.history[\"val_loss\"]\n",
    "\n",
    "# Calculate the mean of test loss for all epochs\n",
    "mean_all_test_loss_augmented = np.mean(all_test_losses)\n",
    "\n",
    "print(f\"Mean Test Loss for Model Trained with Augmentations for All Epochs: {mean_all_test_loss_augmented}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Accuracy (last 5 epochs, with augmentations): 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# Access the test accuracy for each epoch\n",
    "test_accuracy_augmented = history_augmented.history['val_accuracy']\n",
    "\n",
    "# Calculate the average of test accuracy for the last 5 epochs\n",
    "average_test_accuracy_augmented_last_5_epochs = np.mean(test_accuracy_augmented[-5:])\n",
    "\n",
    "print(f\"Average Test Accuracy (last 5 epochs, with augmentations): {average_test_accuracy_augmented_last_5_epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlzoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
